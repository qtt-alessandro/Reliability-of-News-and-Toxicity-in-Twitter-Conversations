<p align="center">
<img src=https://github.com/AMLSapienza/Final_Project/blob/main/data/sapienza_logo.jpg width="100"/>
 </p>
  
  <p align="center">
  <b>Reliability of News and Toxicity in Twitter Conversations<br />
La Sapienza University of Rome <br />
<b>  <br />
Alessandro Quattrociocchi, Gabriele Etta, Michele Avalle, Matteo Cinelli, Walter Quattrociocchi
</p>
  
  

## Abstract
Social media platforms like Twitter play a pivotal role in public debates. Recent studies showed that users online tend to join groups of like-minded peers, called echo chambers, in which they frame and reinforce a shared narrative.  
Such a polarized configuration may trigger heated debates and foment misinformation spreading.
In this work, we explore the interplay between the systematic spreading of misinformation and the emergence of toxic conversations.
We perform a thorough quantitative analysis on 3.3M comments by more than 1M unique users from 25K conversations involving 60 news outlets active on Twitter from January 2020 to April 2022.
By tagging the news triggering the conversation with a specific reliability score provided by an independent fact-checking organization (NewsGuard), we perform a network-based analysis of the structure of toxic conversations on Twitter. 
We find that users using toxic language are few and evenly distributed over the entire reliability score range, showing no significant evidence for the interplay between toxic speech and misinformation spreading.

  

  
  
  
  
<p align="center">
<img src="[https://github.com/AMLSapienza/Final_Project/blob/main/data/im_presentation.png](https://github.com/qtt-alessandro/Reliability-of-News-and-Toxicity-in-Twitter-Conversations/blob/main/code_R/figures/ass_dist_plot.pdf)" width="500"/ >
</p>
 
