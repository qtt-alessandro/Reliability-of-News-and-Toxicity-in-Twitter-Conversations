{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "import lzma\n",
    "import numpy as np\n",
    "import ast\n",
    "import pickle\n",
    "import collections\n",
    "from fake_outlets_list import fake_outlets_timelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all files TRUE or FALSE from domain folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_timelines_from_source_folder(reliability):\n",
    "    if reliability == True:\n",
    "        outlets = ['immunizeorg','NewsOn6', 'KyivPost', 'KyivIndependent', 'CNN', 'FoxNews',\n",
    "        'parentsmagazine', 'nbc6', 'CBSLA', 'esquire', 'TheMarySue', 'dailyherald', 'voxdotcom',\n",
    "        'NYDailyNews', 'USATODAY','WIRED', 'NPR', 'nytimes', 'GayCityNews', 'IndianCountry', 'blackenterprise',\n",
    "        'VoceroPR', 'abc15']\n",
    "        path = '/Users/alessandroquattrociocchi/Documents/data/Twitter/timelines_labelled_newsguard/timelines_TRUE/'\n",
    "    elif reliability == False:\n",
    "        outlets = fake_outlets_timelines\n",
    "        path = '/Users/alessandroquattrociocchi/Documents/data/Twitter/timelines_labelled_newsguard/timelines_FAKE/'\n",
    "\n",
    "    comments_per_outlet = {}\n",
    "    for outlet in tqdm(outlets):\n",
    "        all_files = glob.glob(os.path.join(path + str(outlet) , \"*.csv\"))\n",
    "        li = []\n",
    "        for filename in all_files:\n",
    "            df = pd.read_csv(filename, index_col=None, header=0, low_memory=False)\n",
    "            \n",
    "            li.append(df)\n",
    "        comments_per_outlet[str(outlet)]  = li\n",
    "    return comments_per_outlet, outlets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_page_timeline(df):\n",
    "        #columns to keep in restricted dataset\n",
    "        if 'referenced_tweets' in df.columns:\n",
    "                cols_to_keep = ['text', 'id', 'created_at',\n",
    "                        'referenced_tweets', 'lang',\n",
    "                        'conversation_id', 'author_id', \n",
    "                        'public_metrics']\n",
    "                \n",
    "                df = df[cols_to_keep]\n",
    "                #selecting retweets only\n",
    "                df = df[df['referenced_tweets'].isnull()]\n",
    "                #reset the index\n",
    "                df = df.reset_index(drop=True)\n",
    "\n",
    "                #adding new columns with tweets metrics\n",
    "                df['retweet_count'] = np.nan\n",
    "                df['reply_count'] = np.nan\n",
    "                df['like_count'] = np.nan \n",
    "                df['quote_count'] = np.nan\n",
    "\n",
    "                #extracting the metrics from the public metrics json\n",
    "                for row in range(df.shape[0]):\n",
    "\n",
    "                        tmp_dict_metrics = ast.literal_eval(df['public_metrics'][row])\n",
    "                        retweet_count = tmp_dict_metrics['retweet_count']\n",
    "                        reply_count = tmp_dict_metrics['reply_count']\n",
    "                        like_count  = tmp_dict_metrics['like_count']\n",
    "                        quote_count = tmp_dict_metrics['quote_count']\n",
    "\n",
    "                        df.at[row, 'retweet_count'] = retweet_count\n",
    "                        df.at[row, 'reply_count'] = reply_count\n",
    "                        df.at[row, 'like_count'] = like_count\n",
    "                        df.at[row, 'quote_count'] = quote_count\n",
    "                return df\n",
    "        else: \n",
    "                cols_to_keep = ['text', 'id', 'created_at','lang',\n",
    "                'conversation_id', 'author_id', \n",
    "                'public_metrics']\n",
    "                \n",
    "                df = df[cols_to_keep]\n",
    "                df = df.reset_index(drop=True)\n",
    "\n",
    "                #adding new columns with tweets metrics\n",
    "                df['retweet_count'] = np.nan\n",
    "                df['reply_count'] = np.nan\n",
    "                df['like_count'] = np.nan \n",
    "                df['quote_count'] = np.nan\n",
    "\n",
    "                #extracting the metrics from the public metrics json\n",
    "                for row in range(df.shape[0]):\n",
    "\n",
    "                        tmp_dict_metrics = ast.literal_eval(df['public_metrics'][row])\n",
    "                        retweet_count = tmp_dict_metrics['retweet_count']\n",
    "                        reply_count = tmp_dict_metrics['reply_count']\n",
    "                        like_count  = tmp_dict_metrics['like_count']\n",
    "                        quote_count = tmp_dict_metrics['quote_count']\n",
    "\n",
    "                        df.at[row, 'retweet_count'] = retweet_count\n",
    "                        df.at[row, 'reply_count'] = reply_count\n",
    "                        df.at[row, 'like_count'] = like_count\n",
    "                        df.at[row, 'quote_count'] = quote_count\n",
    "        return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholding_cascade(df,lower_threshold, ascending=False):\n",
    "        df = df[df['reply_count']>=lower_threshold]\n",
    "        df = df.sort_values(by=['reply_count'],ascending=ascending)\n",
    "        df = df.reset_index(drop=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_lzma_pickle(df, address):\n",
    "    with lzma.open(address, \"wb\") as f:\n",
    "        pickle.dump(df, f)\n",
    "    print('pickle file correctly compressed and saved...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa Pipeline importa tutte le timelines, ripulisce il campo delle reference e ordina il dataset prendendo tutti i post che hanno ricevuto un numero di commenti maggiori di 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [00:15<00:00,  9.17it/s]\n"
     ]
    }
   ],
   "source": [
    "#timelines_T, outlets = load_all_timelines_from_source_folder(reliability = True)\n",
    "\n",
    "timelines_F, outlets = load_all_timelines_from_source_folder(reliability = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [00:41<00:00,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Comments:  20380661.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "comments_dict = {}\n",
    "total_comments = 0 \n",
    "\n",
    "for outlet in tqdm(outlets):\n",
    "    if len(timelines_F[outlet]) > 0:\n",
    "        tmp_df = preprocessing_page_timeline(timelines_F[outlet][0])\n",
    "        tmp_df = thresholding_cascade(tmp_df, lower_threshold=20)\n",
    "        total_comments += tmp_df['reply_count'].sum()\n",
    "        if tmp_df.shape[0] > 0:\n",
    "            comments_dict[outlet] = tmp_df\n",
    "print('Total Number of Comments: ', total_comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>lang</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>public_metrics</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@Franklin_Graham: \"President Trump will go do...</td>\n",
       "      <td>1339028078069239809</td>\n",
       "      <td>2020-12-16T02:02:26.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>1339028078069239809</td>\n",
       "      <td>457984599</td>\n",
       "      <td>{'retweet_count': 8134, 'reply_count': 20334, ...</td>\n",
       "      <td>8134.0</td>\n",
       "      <td>20334.0</td>\n",
       "      <td>59476.0</td>\n",
       "      <td>2684.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The elitist snobs in the fashion press have ke...</td>\n",
       "      <td>1342440129953202177</td>\n",
       "      <td>2020-12-25T12:00:42.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>1342440129953202177</td>\n",
       "      <td>457984599</td>\n",
       "      <td>{'retweet_count': 5844, 'reply_count': 16540, ...</td>\n",
       "      <td>5844.0</td>\n",
       "      <td>16540.0</td>\n",
       "      <td>32077.0</td>\n",
       "      <td>2395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Let's roll. https://t.co/lxmoxLEpEa</td>\n",
       "      <td>1325965921886867457</td>\n",
       "      <td>2020-11-10T00:58:05.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>1325965921886867457</td>\n",
       "      <td>457984599</td>\n",
       "      <td>{'retweet_count': 11061, 'reply_count': 8233, ...</td>\n",
       "      <td>11061.0</td>\n",
       "      <td>8233.0</td>\n",
       "      <td>65431.0</td>\n",
       "      <td>1873.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why wait? https://t.co/Icl16emcV2</td>\n",
       "      <td>1316394269503098880</td>\n",
       "      <td>2020-10-14T15:03:45.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>1316394269503098880</td>\n",
       "      <td>457984599</td>\n",
       "      <td>{'retweet_count': 1961, 'reply_count': 7703, '...</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>7703.0</td>\n",
       "      <td>12672.0</td>\n",
       "      <td>1842.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michelle Obama says she is \"dealing with some ...</td>\n",
       "      <td>1291078360504754176</td>\n",
       "      <td>2020-08-05T18:27:22.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>1291078360504754176</td>\n",
       "      <td>457984599</td>\n",
       "      <td>{'retweet_count': 935, 'reply_count': 7596, 'l...</td>\n",
       "      <td>935.0</td>\n",
       "      <td>7596.0</td>\n",
       "      <td>3937.0</td>\n",
       "      <td>2515.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tom Fitton: Americans weren’t generally aware ...</td>\n",
       "      <td>1310772464650260480</td>\n",
       "      <td>2020-09-29T02:44:43.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>1310772464650260480</td>\n",
       "      <td>457984599</td>\n",
       "      <td>{'retweet_count': 9021, 'reply_count': 6986, '...</td>\n",
       "      <td>9021.0</td>\n",
       "      <td>6986.0</td>\n",
       "      <td>26140.0</td>\n",
       "      <td>676.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Please remain standing for the National Anthe...</td>\n",
       "      <td>1338586645151543298</td>\n",
       "      <td>2020-12-14T20:48:20.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>1338586645151543298</td>\n",
       "      <td>457984599</td>\n",
       "      <td>{'retweet_count': 1632, 'reply_count': 6804, '...</td>\n",
       "      <td>1632.0</td>\n",
       "      <td>6804.0</td>\n",
       "      <td>4186.0</td>\n",
       "      <td>3565.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>President Donald Trump has received more popul...</td>\n",
       "      <td>1325129980691558400</td>\n",
       "      <td>2020-11-07T17:36:21.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>1325129980691558400</td>\n",
       "      <td>457984599</td>\n",
       "      <td>{'retweet_count': 1408, 'reply_count': 6534, '...</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>6534.0</td>\n",
       "      <td>5469.0</td>\n",
       "      <td>1439.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ouch. https://t.co/uwCChJoX2V</td>\n",
       "      <td>1325878050035298305</td>\n",
       "      <td>2020-11-09T19:08:55.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>1325878050035298305</td>\n",
       "      <td>457984599</td>\n",
       "      <td>{'retweet_count': 9168, 'reply_count': 6387, '...</td>\n",
       "      <td>9168.0</td>\n",
       "      <td>6387.0</td>\n",
       "      <td>49671.0</td>\n",
       "      <td>1997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Every American needs to see Joe Biden's latest...</td>\n",
       "      <td>1242143644917866498</td>\n",
       "      <td>2020-03-23T17:38:17.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>1242143644917866498</td>\n",
       "      <td>457984599</td>\n",
       "      <td>{'retweet_count': 8122, 'reply_count': 5420, '...</td>\n",
       "      <td>8122.0</td>\n",
       "      <td>5420.0</td>\n",
       "      <td>20960.0</td>\n",
       "      <td>2291.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                   id  \\\n",
       "0  .@Franklin_Graham: \"President Trump will go do...  1339028078069239809   \n",
       "1  The elitist snobs in the fashion press have ke...  1342440129953202177   \n",
       "2                Let's roll. https://t.co/lxmoxLEpEa  1325965921886867457   \n",
       "3                  Why wait? https://t.co/Icl16emcV2  1316394269503098880   \n",
       "4  Michelle Obama says she is \"dealing with some ...  1291078360504754176   \n",
       "5  Tom Fitton: Americans weren’t generally aware ...  1310772464650260480   \n",
       "6  \"Please remain standing for the National Anthe...  1338586645151543298   \n",
       "7  President Donald Trump has received more popul...  1325129980691558400   \n",
       "8                      Ouch. https://t.co/uwCChJoX2V  1325878050035298305   \n",
       "9  Every American needs to see Joe Biden's latest...  1242143644917866498   \n",
       "\n",
       "                 created_at referenced_tweets lang      conversation_id  \\\n",
       "0  2020-12-16T02:02:26.000Z               NaN   en  1339028078069239809   \n",
       "1  2020-12-25T12:00:42.000Z               NaN   en  1342440129953202177   \n",
       "2  2020-11-10T00:58:05.000Z               NaN   en  1325965921886867457   \n",
       "3  2020-10-14T15:03:45.000Z               NaN   en  1316394269503098880   \n",
       "4  2020-08-05T18:27:22.000Z               NaN   en  1291078360504754176   \n",
       "5  2020-09-29T02:44:43.000Z               NaN   en  1310772464650260480   \n",
       "6  2020-12-14T20:48:20.000Z               NaN   en  1338586645151543298   \n",
       "7  2020-11-07T17:36:21.000Z               NaN   en  1325129980691558400   \n",
       "8  2020-11-09T19:08:55.000Z               NaN   en  1325878050035298305   \n",
       "9  2020-03-23T17:38:17.000Z               NaN   en  1242143644917866498   \n",
       "\n",
       "   author_id                                     public_metrics  \\\n",
       "0  457984599  {'retweet_count': 8134, 'reply_count': 20334, ...   \n",
       "1  457984599  {'retweet_count': 5844, 'reply_count': 16540, ...   \n",
       "2  457984599  {'retweet_count': 11061, 'reply_count': 8233, ...   \n",
       "3  457984599  {'retweet_count': 1961, 'reply_count': 7703, '...   \n",
       "4  457984599  {'retweet_count': 935, 'reply_count': 7596, 'l...   \n",
       "5  457984599  {'retweet_count': 9021, 'reply_count': 6986, '...   \n",
       "6  457984599  {'retweet_count': 1632, 'reply_count': 6804, '...   \n",
       "7  457984599  {'retweet_count': 1408, 'reply_count': 6534, '...   \n",
       "8  457984599  {'retweet_count': 9168, 'reply_count': 6387, '...   \n",
       "9  457984599  {'retweet_count': 8122, 'reply_count': 5420, '...   \n",
       "\n",
       "   retweet_count  reply_count  like_count  quote_count  \n",
       "0         8134.0      20334.0     59476.0       2684.0  \n",
       "1         5844.0      16540.0     32077.0       2395.0  \n",
       "2        11061.0       8233.0     65431.0       1873.0  \n",
       "3         1961.0       7703.0     12672.0       1842.0  \n",
       "4          935.0       7596.0      3937.0       2515.0  \n",
       "5         9021.0       6986.0     26140.0        676.0  \n",
       "6         1632.0       6804.0      4186.0       3565.0  \n",
       "7         1408.0       6534.0      5469.0       1439.0  \n",
       "8         9168.0       6387.0     49671.0       1997.0  \n",
       "9         8122.0       5420.0     20960.0       2291.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_dict['BreitbartNews'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvare il dataset di timelines in forma aggregata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle file correctly compressed and saved...\n"
     ]
    }
   ],
   "source": [
    "# TRUE\n",
    "write_lzma_pickle(comments_dict,'/Users/alessandroquattrociocchi/Desktop/timelines_aggregated_F.pickle.xz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAKE\n",
    "#write_lzma_pickle(comments_dict,'/Users/alessandroquattrociocchi/Desktop/timelines_aggregated_F.pickle.xz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['immunizeorg','NewsOn6', 'KyivPost', 'KyivIndependent', 'CNN', 'FoxNews',\n",
    "'parentsmagazine', 'nbc6', 'CBSLA', 'esquire', 'TheMarySue', 'dailyherald', 'voxdotcom',\n",
    "'NYDailyNews', 'USATODAY','WIRED', 'NPR', 'nytimes', 'GayCityNews', 'IndianCountry', 'blackenterprise',\n",
    "'VoceroPR', 'abc15', 'ascienthusiast', 'newsmax', 'BIZPACReview', 'drchrisnorthrup', 'healthychildren', 'NewsBecker', 'chicksonright', 'scarymommy', 'EpochTimes', 'ebonymag',\n",
    "'GovMikeHuckabee', 'twpundit', 'TheGoodGodAbove', 'thetnstar', 'houstonpress', 'WGNRadio', 'nypost', 'tassagency_en', 'globaltimesnews', 'wearemitu', 'percolately',\n",
    "'bright_side_me', 'GeorgiaStarNews', 'mindys4Biden', 'ChinaDailyUSA', 'MediaTakeoutTV', 'NationalMemo', 'newsandguts', 'theinquisitr', 'digg', 'VoiceofPD', 'nra',\n",
    "'mercola', 'veteranstoday', 'thedailybanter', 'unhealthytruth', 'Greg_Palast', 'townhallcom', 'lifebiomedguru', 'V_of_Europe', 'voguemagazine', 'TheOhioStar',\n",
    "'MadWorldNews', 'PoliTribune', 'strange_sounds', 'realdennislynch', 'NatEnquirer', 'thrive', 'PanData19', 'AliciaFixLuke', 'amerdailyindy', 'FDRLST', 'LiveAction', 'LifeNewsHQ', 'WayneDupreeShow']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43dc96d61c1ca8432abb54e178d8b53c2b68e12f28571b70ab00467b01e23138"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('thesis_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
